{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfVX3g3mpmSz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9562f1-d6eb-4283-fa7f-18ee9c95dedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "import csv\n",
        "import os\n",
        "import numpy as np\n",
        "import h5py\n",
        "import skimage.io\n",
        "from sklearn.utils import shuffle\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "random.seed(5218)\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eB1bMG07YauJ",
        "outputId": "10e42ce6-e4f7-4055-b23e-24b9ba8cac42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyiJ9-sAATKk"
      },
      "source": [
        "Preparing dataset (CK+)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "qDQFHEVG_69W",
        "outputId": "6cb09a66-7ca2-4d93-e3bc-3fb0ca9ba008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "with ZipFile('/content/drive/MyDrive/Datasets/CK+.zip') as zipObj:\n",
        "  zipObj.extractall('/content/CK+')\n",
        "\n",
        "ck_path = 'CK+'\n",
        "\n",
        "anger_path = os.path.join(ck_path, 'anger')\n",
        "disgust_path = os.path.join(ck_path, 'disgust')\n",
        "fear_path = os.path.join(ck_path, 'fear')\n",
        "happy_path = os.path.join(ck_path, 'happy')\n",
        "sadness_path = os.path.join(ck_path, 'sadness')\n",
        "surprise_path = os.path.join(ck_path, 'surprise')\n",
        "contempt_path = os.path.join(ck_path, 'contempt')\n",
        "\n",
        "data_x = []\n",
        "data_y = []\n",
        "\n",
        "# datapath = os.path.join('data','CK_data.h5')\n",
        "if not os.path.exists(os.path.dirname(datapath)):\n",
        "    os.makedirs(os.path.dirname(datapath))\n",
        "\n",
        "files = os.listdir(anger_path)\n",
        "files.sort()\n",
        "for filename in files:\n",
        "    I = skimage.io.imread(os.path.join(anger_path,filename))\n",
        "    data_x.append(I.tolist())\n",
        "    data_y.append(0)\n",
        "\n",
        "files = os.listdir(disgust_path)\n",
        "files.sort()\n",
        "for filename in files:\n",
        "    I = skimage.io.imread(os.path.join(disgust_path,filename))\n",
        "    data_x.append(I.tolist())\n",
        "    data_y.append(1)\n",
        "\n",
        "files = os.listdir(fear_path)\n",
        "files.sort()\n",
        "for filename in files:\n",
        "    I = skimage.io.imread(os.path.join(fear_path,filename))\n",
        "    data_x.append(I.tolist())\n",
        "    data_y.append(2)\n",
        "\n",
        "files = os.listdir(happy_path)\n",
        "files.sort()\n",
        "for filename in files:\n",
        "    I = skimage.io.imread(os.path.join(happy_path,filename))\n",
        "    data_x.append(I.tolist())\n",
        "    data_y.append(3)\n",
        "\n",
        "files = os.listdir(sadness_path)\n",
        "files.sort()\n",
        "for filename in files:\n",
        "    I = skimage.io.imread(os.path.join(sadness_path,filename))\n",
        "    data_x.append(I.tolist())\n",
        "    data_y.append(4)\n",
        "\n",
        "files = os.listdir(surprise_path)\n",
        "files.sort()\n",
        "for filename in files:\n",
        "    I = skimage.io.imread(os.path.join(surprise_path,filename))\n",
        "    data_x.append(I.tolist())\n",
        "    data_y.append(5)\n",
        "\n",
        "files = os.listdir(contempt_path)\n",
        "files.sort()\n",
        "for filename in files:\n",
        "    I = skimage.io.imread(os.path.join(contempt_path,filename))\n",
        "    data_x.append(I.tolist())\n",
        "    data_y.append(6)\n",
        "\n",
        "# print(np.shape(data_x))\n",
        "# print(np.shape(data_y))\n",
        "\n",
        "data_x, data_y = shuffle(data_x, data_y, random_state=0)\n",
        "img_index = random.randint(0, np.shape(data_x)[0])\n",
        "plt.imshow(data_x[img_index])\n",
        "print(data_y[img_index])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-dtgWQPAoa2"
      },
      "source": [
        "Defining Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "_BjnE_R7Ar_j",
        "outputId": "36ed401a-0a82-4cf6-a5ca-fbaa990af472"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c5dabc8b6817>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m train_datagen = tf.keras.processing.image.ImageDataGenerator(\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mrotation_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mshear_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras' has no attribute 'processing'"
          ]
        }
      ],
      "source": [
        "input_size = np.shape(data_x)[1] \n",
        "dataset_size = np.shape(data_x)[0]\n",
        "train_size = int(dataset_size * 0.8)\n",
        "train_x = data_x[0:train_size]\n",
        "train_y = data_y[0:train_size]\n",
        "\n",
        "test_size = int(dataset_size * 0.1)\n",
        "test_x = data_x[train_size: dataset_size]\n",
        "test_y = data_y[train_size: dataset_size]\n",
        "\n",
        "test_x = data_x[train_size:train_size + test_size]\n",
        "test_y = data_y[train_size:train_size + test_size]\n",
        "\n",
        "val_x = data_x[train_size + test_size: dataset_size]\n",
        "val_y = data_y[train_size + test_size: dataset_size]\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range = 10,\n",
        "    shear_range = 10, \n",
        "    zoom_range = 0.1,\n",
        "    fill_mode = 'reflect',\n",
        "    horizontal_flip = True)\n",
        "\n",
        "print(input_size)\n",
        "print(np.shape(train_x))\n",
        "print(np.shape(test_x))\n",
        "print(np.shape(val_x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLx-wcCqA6JN"
      },
      "outputs": [],
      "source": [
        "def Model1(input_size, train_x, train_y, epochs, test_x, test_y, loss_func=\"S\"):\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), input_shape=(input_size, input_size, 1), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(units=128, activation='relu'))\n",
        "  model.add(layers.Dense(units=128, activation='sigmoid'))\n",
        "\n",
        "  if loss_func == \"C\":\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  elif loss_func == \"S\":\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss=loss,\n",
        "                metrics=['accuracy'])\n",
        "  history = model.fit(train_x, train_y, epochs=epochs, validation_data=(test_x, test_y))\n",
        "  return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "jHWmBAHcGYRF",
        "outputId": "20369458-d1eb-4d5c-9c9b-a000ac13caba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 11s 55ms/step - loss: 11.7926 - accuracy: 0.3138 - val_loss: 1.2403 - val_accuracy: 0.6224\n",
            "Epoch 2/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.7426 - accuracy: 0.7309 - val_loss: 0.4325 - val_accuracy: 0.8673\n",
            "Epoch 3/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.3142 - accuracy: 0.9171 - val_loss: 0.2382 - val_accuracy: 0.9490\n",
            "Epoch 4/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1444 - accuracy: 0.9643 - val_loss: 0.1371 - val_accuracy: 0.9796\n",
            "Epoch 5/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.1084 - accuracy: 0.9668 - val_loss: 0.0790 - val_accuracy: 0.9796\n",
            "Epoch 6/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0449 - accuracy: 0.9936 - val_loss: 0.1027 - val_accuracy: 0.9796\n",
            "Epoch 7/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0353 - accuracy: 0.9936 - val_loss: 0.0778 - val_accuracy: 0.9898\n",
            "Epoch 8/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0228 - accuracy: 0.9987 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9949 - val_loss: 0.0468 - val_accuracy: 0.9898\n",
            "Epoch 10/10\n",
            "25/25 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0296 - val_accuracy: 0.9898\n",
            "4/4 - 0s - loss: 0.0137 - accuracy: 1.0000 - 68ms/epoch - 17ms/step\n",
            "0.01372214313596487 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "loss = \"S\"\n",
        "model, history = Model1(input_size, train_x, train_y, epochs, test_x, test_y, loss)\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(val_x, val_y, verbose=2)\n",
        "print(test_loss, test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCsaC51_J22f",
        "outputId": "6259dd21-0297-44c3-f9e8-76b2b7f20a37"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of images in Training set: 32298\n",
            "Number of images in Test set: 3589\n"
          ]
        }
      ],
      "source": [
        "with ZipFile('/content/drive/MyDrive/Datasets/fer2013.csv.zip') as zipObj:\n",
        "  zipObj.extractall('/content/FER2013')\n",
        "\n",
        "def load_data(dataset_path):\n",
        "  \n",
        "  #classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprsie', 'Neutral']  #We will be dealing with seven different types of emotions.\n",
        "\n",
        "  data = []\n",
        "  test_data = []\n",
        "  test_labels = []\n",
        "  labels =[]\n",
        "\n",
        "  with open(dataset_path, 'r') as file:\n",
        "      for line_no, line in enumerate(file.readlines()):\n",
        "          if 0 < line_no <= 35887:\n",
        "            curr_class, line, set_type = line.split(',')\n",
        "            image_data = np.asarray([int(x) for x in line.split()]).reshape(48, 48)#Creating a list out of the string then converting it into a 2-Dimensional numpy array.\n",
        "            image_data =image_data.astype(np.uint8)/255.0\n",
        "            \n",
        "            if (set_type.strip() == 'PrivateTest'):\n",
        "              \n",
        "              test_data.append(image_data)\n",
        "              test_labels.append(curr_class)\n",
        "            else:\n",
        "              data.append(image_data)\n",
        "              labels.append(curr_class)\n",
        "      \n",
        "      test_data = np.expand_dims(test_data, -1)\n",
        "      test_labels = tf.keras.utils.to_categorical(test_labels, num_classes = 7)\n",
        "      data = np.expand_dims(data, -1)   \n",
        "      labels = tf.keras.utils.to_categorical(labels, num_classes = 7)\n",
        "    \n",
        "      return np.array(data), np.array(labels), np.array(test_data), np.array(test_labels)\n",
        "\n",
        "dataset_path = \"/content/FER2013/fer2013.csv\" \n",
        "train_data, train_labels, test_data, test_labels = load_data(dataset_path)\n",
        "#train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size = test_size,random_state = seed)\n",
        "\n",
        "print(\"Number of images in Training set:\", len(train_data))\n",
        "print(\"Number of images in Test set:\", len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kl-JPJtNCSB"
      },
      "outputs": [],
      "source": [
        "def Model1(input_size, train_x, train_y, epochs, test_x, test_y, loss_func=\"S\"):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(48, 48, 1), kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "    model.add(layers.Conv2D(64, (3, 3), padding='same',activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(2, 2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "      \n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "      \n",
        "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(256, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "      \n",
        "    model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Conv2D(512, (3, 3), padding='same', activation='relu'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "      \n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(512, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(256, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(128, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.Dense(7, activation='softmax'))\n",
        "\n",
        "    if loss_func == \"C\":\n",
        "      loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    elif loss_func == \"S\":\n",
        "      loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss=loss,\n",
        "                  metrics=['accuracy'])\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "    history = model.fit(train_x, train_y, epochs=epochs, validation_data=(test_x, test_y), callbacks=[early_stopping])\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fquCjiVhM9QI",
        "outputId": "a191cdd9-c869-4e28-e433-c024253b395d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1010/1010 [==============================] - 36s 24ms/step - loss: 2.0085 - accuracy: 0.2171 - val_loss: 1.8448 - val_accuracy: 0.2449\n",
            "Epoch 2/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.8437 - accuracy: 0.2479 - val_loss: 1.8352 - val_accuracy: 0.2449\n",
            "Epoch 3/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.8252 - accuracy: 0.2498 - val_loss: 1.8167 - val_accuracy: 0.2449\n",
            "Epoch 4/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.8170 - accuracy: 0.2496 - val_loss: 1.8119 - val_accuracy: 0.2449\n",
            "Epoch 5/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.8092 - accuracy: 0.2498 - val_loss: 1.7978 - val_accuracy: 0.2449\n",
            "Epoch 6/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.8061 - accuracy: 0.2494 - val_loss: 1.8715 - val_accuracy: 0.2446\n",
            "Epoch 7/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.7827 - accuracy: 0.2643 - val_loss: 1.8365 - val_accuracy: 0.2455\n",
            "Epoch 8/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.7702 - accuracy: 0.2732 - val_loss: 1.7356 - val_accuracy: 0.2878\n",
            "Epoch 9/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.7379 - accuracy: 0.2893 - val_loss: 1.7306 - val_accuracy: 0.2686\n",
            "Epoch 10/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.6778 - accuracy: 0.3132 - val_loss: 1.7222 - val_accuracy: 0.2750\n",
            "Epoch 11/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.6315 - accuracy: 0.3504 - val_loss: 1.6348 - val_accuracy: 0.3399\n",
            "Epoch 12/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.5866 - accuracy: 0.3673 - val_loss: 1.5161 - val_accuracy: 0.3968\n",
            "Epoch 13/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.5531 - accuracy: 0.3841 - val_loss: 1.5215 - val_accuracy: 0.4079\n",
            "Epoch 14/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.5182 - accuracy: 0.3935 - val_loss: 1.4781 - val_accuracy: 0.3951\n",
            "Epoch 15/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.4983 - accuracy: 0.4011 - val_loss: 1.4261 - val_accuracy: 0.4152\n",
            "Epoch 16/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.4711 - accuracy: 0.4110 - val_loss: 1.4165 - val_accuracy: 0.4263\n",
            "Epoch 17/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.4423 - accuracy: 0.4187 - val_loss: 1.3885 - val_accuracy: 0.4280\n",
            "Epoch 18/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.4164 - accuracy: 0.4305 - val_loss: 1.3566 - val_accuracy: 0.4447\n",
            "Epoch 19/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.3999 - accuracy: 0.4374 - val_loss: 1.4073 - val_accuracy: 0.4227\n",
            "Epoch 20/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.3835 - accuracy: 0.4412 - val_loss: 1.4303 - val_accuracy: 0.3998\n",
            "Epoch 21/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.3626 - accuracy: 0.4466 - val_loss: 1.3608 - val_accuracy: 0.4310\n",
            "Epoch 22/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.3464 - accuracy: 0.4590 - val_loss: 1.3353 - val_accuracy: 0.4687\n",
            "Epoch 23/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.3314 - accuracy: 0.4608 - val_loss: 1.3471 - val_accuracy: 0.4675\n",
            "Epoch 24/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.3136 - accuracy: 0.4675 - val_loss: 1.2832 - val_accuracy: 0.4765\n",
            "Epoch 25/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.2997 - accuracy: 0.4780 - val_loss: 1.2863 - val_accuracy: 0.4951\n",
            "Epoch 26/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.2808 - accuracy: 0.4879 - val_loss: 1.2770 - val_accuracy: 0.4882\n",
            "Epoch 27/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.2751 - accuracy: 0.4953 - val_loss: 1.2984 - val_accuracy: 0.4929\n",
            "Epoch 28/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.2506 - accuracy: 0.5089 - val_loss: 1.2681 - val_accuracy: 0.5113\n",
            "Epoch 29/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.2395 - accuracy: 0.5193 - val_loss: 1.2618 - val_accuracy: 0.5032\n",
            "Epoch 30/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.2178 - accuracy: 0.5283 - val_loss: 1.2082 - val_accuracy: 0.5428\n",
            "Epoch 31/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.1995 - accuracy: 0.5382 - val_loss: 1.2358 - val_accuracy: 0.5238\n",
            "Epoch 32/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.1890 - accuracy: 0.5442 - val_loss: 1.2011 - val_accuracy: 0.5414\n",
            "Epoch 33/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.1739 - accuracy: 0.5482 - val_loss: 1.3389 - val_accuracy: 0.5049\n",
            "Epoch 34/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.1571 - accuracy: 0.5549 - val_loss: 1.2557 - val_accuracy: 0.5233\n",
            "Epoch 35/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.1434 - accuracy: 0.5637 - val_loss: 1.2235 - val_accuracy: 0.5497\n",
            "Epoch 36/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.1377 - accuracy: 0.5679 - val_loss: 1.1827 - val_accuracy: 0.5673\n",
            "Epoch 37/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.1211 - accuracy: 0.5733 - val_loss: 1.1957 - val_accuracy: 0.5656\n",
            "Epoch 38/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.1058 - accuracy: 0.5821 - val_loss: 1.2077 - val_accuracy: 0.5417\n",
            "Epoch 39/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.0940 - accuracy: 0.5871 - val_loss: 1.1993 - val_accuracy: 0.5651\n",
            "Epoch 40/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.0900 - accuracy: 0.5909 - val_loss: 1.1909 - val_accuracy: 0.5525\n",
            "Epoch 41/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.0679 - accuracy: 0.6012 - val_loss: 1.2163 - val_accuracy: 0.5408\n",
            "Epoch 42/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.0501 - accuracy: 0.6016 - val_loss: 1.1920 - val_accuracy: 0.5678\n",
            "Epoch 43/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.0520 - accuracy: 0.6105 - val_loss: 1.1742 - val_accuracy: 0.5756\n",
            "Epoch 44/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.0314 - accuracy: 0.6139 - val_loss: 1.1716 - val_accuracy: 0.5782\n",
            "Epoch 45/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.0425 - accuracy: 0.6135 - val_loss: 1.1864 - val_accuracy: 0.5528\n",
            "Epoch 46/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.0245 - accuracy: 0.6223 - val_loss: 1.1590 - val_accuracy: 0.5729\n",
            "Epoch 47/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 1.0173 - accuracy: 0.6227 - val_loss: 1.2521 - val_accuracy: 0.5514\n",
            "Epoch 48/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 1.0046 - accuracy: 0.6302 - val_loss: 1.1420 - val_accuracy: 0.6004\n",
            "Epoch 49/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.9995 - accuracy: 0.6363 - val_loss: 1.1543 - val_accuracy: 0.5896\n",
            "Epoch 50/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.9711 - accuracy: 0.6406 - val_loss: 1.1797 - val_accuracy: 0.5907\n",
            "Epoch 51/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.9765 - accuracy: 0.6448 - val_loss: 1.2820 - val_accuracy: 0.5258\n",
            "Epoch 52/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.9589 - accuracy: 0.6490 - val_loss: 1.2024 - val_accuracy: 0.5848\n",
            "Epoch 53/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.9584 - accuracy: 0.6510 - val_loss: 1.2510 - val_accuracy: 0.6021\n",
            "Epoch 54/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 0.9555 - accuracy: 0.6516 - val_loss: 1.2589 - val_accuracy: 0.5770\n",
            "Epoch 55/100\n",
            "1010/1010 [==============================] - 25s 24ms/step - loss: 0.9482 - accuracy: 0.6572 - val_loss: 1.1501 - val_accuracy: 0.6013\n",
            "Epoch 56/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.9283 - accuracy: 0.6663 - val_loss: 1.2264 - val_accuracy: 0.5862\n",
            "Epoch 57/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.9116 - accuracy: 0.6722 - val_loss: 1.3355 - val_accuracy: 0.5712\n",
            "Epoch 58/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 0.9101 - accuracy: 0.6708 - val_loss: 1.2755 - val_accuracy: 0.5773\n",
            "Epoch 59/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8972 - accuracy: 0.6783 - val_loss: 1.1897 - val_accuracy: 0.5999\n",
            "Epoch 60/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.9069 - accuracy: 0.6798 - val_loss: 1.1473 - val_accuracy: 0.6096\n",
            "Epoch 61/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8891 - accuracy: 0.6821 - val_loss: 1.2902 - val_accuracy: 0.6138\n",
            "Epoch 62/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8799 - accuracy: 0.6861 - val_loss: 1.2949 - val_accuracy: 0.5851\n",
            "Epoch 63/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8763 - accuracy: 0.6936 - val_loss: 1.1911 - val_accuracy: 0.6177\n",
            "Epoch 64/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8641 - accuracy: 0.6950 - val_loss: 1.2167 - val_accuracy: 0.6133\n",
            "Epoch 65/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8661 - accuracy: 0.6951 - val_loss: 1.2266 - val_accuracy: 0.6002\n",
            "Epoch 66/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8413 - accuracy: 0.7066 - val_loss: 1.2326 - val_accuracy: 0.6030\n",
            "Epoch 67/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8395 - accuracy: 0.7022 - val_loss: 1.1689 - val_accuracy: 0.6149\n",
            "Epoch 68/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8435 - accuracy: 0.7082 - val_loss: 1.1642 - val_accuracy: 0.6113\n",
            "Epoch 69/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8436 - accuracy: 0.7092 - val_loss: 1.2169 - val_accuracy: 0.6013\n",
            "Epoch 70/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8283 - accuracy: 0.7147 - val_loss: 1.2951 - val_accuracy: 0.6177\n",
            "Epoch 71/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8147 - accuracy: 0.7214 - val_loss: 1.2845 - val_accuracy: 0.6130\n",
            "Epoch 72/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8196 - accuracy: 0.7199 - val_loss: 1.4858 - val_accuracy: 0.5600\n",
            "Epoch 73/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8139 - accuracy: 0.7217 - val_loss: 1.2621 - val_accuracy: 0.6074\n",
            "Epoch 74/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8272 - accuracy: 0.7187 - val_loss: 1.1923 - val_accuracy: 0.5860\n",
            "Epoch 75/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8036 - accuracy: 0.7255 - val_loss: 1.2629 - val_accuracy: 0.6230\n",
            "Epoch 76/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.8036 - accuracy: 0.7217 - val_loss: 1.2826 - val_accuracy: 0.6169\n",
            "Epoch 77/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7909 - accuracy: 0.7293 - val_loss: 1.2877 - val_accuracy: 0.6194\n",
            "Epoch 78/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7710 - accuracy: 0.7362 - val_loss: 1.2871 - val_accuracy: 0.6166\n",
            "Epoch 79/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7713 - accuracy: 0.7415 - val_loss: 1.4163 - val_accuracy: 0.5968\n",
            "Epoch 80/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7667 - accuracy: 0.7395 - val_loss: 1.3426 - val_accuracy: 0.6183\n",
            "Epoch 81/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7519 - accuracy: 0.7448 - val_loss: 1.3226 - val_accuracy: 0.6208\n",
            "Epoch 82/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7516 - accuracy: 0.7453 - val_loss: 1.3489 - val_accuracy: 0.6269\n",
            "Epoch 83/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7544 - accuracy: 0.7453 - val_loss: 1.2638 - val_accuracy: 0.6272\n",
            "Epoch 84/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7464 - accuracy: 0.7493 - val_loss: 1.2534 - val_accuracy: 0.6280\n",
            "Epoch 85/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 0.7382 - accuracy: 0.7504 - val_loss: 1.3370 - val_accuracy: 0.6258\n",
            "Epoch 86/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 0.7385 - accuracy: 0.7529 - val_loss: 1.3725 - val_accuracy: 0.6186\n",
            "Epoch 87/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 0.7294 - accuracy: 0.7521 - val_loss: 1.3308 - val_accuracy: 0.6222\n",
            "Epoch 88/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 0.7584 - accuracy: 0.7447 - val_loss: 1.2424 - val_accuracy: 0.6110\n",
            "Epoch 89/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 0.7205 - accuracy: 0.7596 - val_loss: 1.3810 - val_accuracy: 0.6124\n",
            "Epoch 90/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7244 - accuracy: 0.7591 - val_loss: 1.4558 - val_accuracy: 0.5684\n",
            "Epoch 91/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.6943 - accuracy: 0.7685 - val_loss: 1.2938 - val_accuracy: 0.6169\n",
            "Epoch 92/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.7015 - accuracy: 0.7671 - val_loss: 1.3573 - val_accuracy: 0.6174\n",
            "Epoch 93/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.6809 - accuracy: 0.7738 - val_loss: 1.3156 - val_accuracy: 0.6213\n",
            "Epoch 94/100\n",
            "1010/1010 [==============================] - 24s 24ms/step - loss: 0.6826 - accuracy: 0.7719 - val_loss: 1.2888 - val_accuracy: 0.6261\n",
            "Epoch 95/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.6854 - accuracy: 0.7747 - val_loss: 1.3027 - val_accuracy: 0.6194\n",
            "Epoch 96/100\n",
            "1010/1010 [==============================] - 24s 23ms/step - loss: 0.6910 - accuracy: 0.7722 - val_loss: 1.2317 - val_accuracy: 0.6152\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "loss_func = \"C\"\n",
        "model, history = Model1(input_size, train_data, train_labels, epochs, test_data, test_labels, loss_func)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZ1R83J2V3HW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "5f8f5a9f-2483-44ab-db33-0881f34acbed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f4c67b8c750>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "from tensorflow.python.lib.io import file_io\n",
        "import pandas as pd\n",
        "\n",
        "train_dataset\t= '/content/FER2013Sep/fer2013_train.csv'\n",
        "eval_dataset \t= '/content/FER2013Sep/fer2013_eval.csv'\n",
        "\n",
        "img_height, img_width = 139, 139\n",
        "\n",
        "with ZipFile('/content/drive/MyDrive/Datasets/fer2013sep.zip') as zipObj:\n",
        "  zipObj.extractall('/content/FER2013Sep')\n",
        "\n",
        "def preprocess_input(x):\n",
        "    x /= 127.5\n",
        "    x -= 1.\n",
        "    return x\n",
        "\n",
        "def get_data(dataset):\n",
        "    file_stream = file_io.FileIO(dataset, mode='r')\n",
        "    data = pd.read_csv(file_stream)\n",
        "    pixels = data['pixels'].tolist()\n",
        "    images = np.empty((len(data), img_height, img_width, 3))\n",
        "    i = 0\n",
        "\n",
        "    for pixel_sequence in pixels:\n",
        "        single_image = [float(pixel) for pixel in pixel_sequence.split(' ')]  \n",
        "        single_image = np.asarray(single_image).reshape(48, 48) \n",
        "        single_image = resize(single_image, (img_height, img_width), order = 3, mode = 'constant') \n",
        "        ret = np.empty((img_height, img_width, 3))  \n",
        "        ret[:, :, 0] = single_image\n",
        "        ret[:, :, 1] = single_image\n",
        "        ret[:, :, 2] = single_image\n",
        "        images[i, :, :, :] = ret\n",
        "        i += 1\n",
        "    \n",
        "    images = preprocess_input(images)\n",
        "    labels = tf.keras.utils.to_categorical(data['emotion'])\n",
        "\n",
        "    return images, labels    \n",
        "\n",
        "train_data_x, train_data_y  = get_data(train_dataset)\n",
        "val_data  = get_data(eval_dataset)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c4CCrm7heMsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    include_top = False,\n",
        "    weights     = 'imagenet',\n",
        "    input_shape = (img_height, img_width, 3))\n",
        "\n",
        "output = base_model.output\n",
        "\n",
        "x = layers.GlobalAveragePooling2D()(output)\n",
        "x = layers.Dense(1024, activation = 'relu')(x)\n",
        "predictions = layers.Dense(7, activation = 'softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs = base_model.input, outputs = predictions)\n",
        "model.summary()\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr = 1e-3, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0), \n",
        "    loss        = 'categorical_crossentropy', \n",
        "    metrics     = ['accuracy'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxnpzvSMfLgS",
        "outputId": "da14f3bf-9173-48bb-d54c-ea8004b12ae3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 139, 139, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 69, 69, 32)   864         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 69, 69, 32)  96          ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 69, 69, 32)   0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 67, 67, 32)   9216        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 67, 67, 32)  96          ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 67, 67, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 67, 67, 64)   18432       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 67, 67, 64)  192         ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 67, 67, 64)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 33, 33, 64)   0           ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 33, 33, 80)   5120        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 33, 33, 80)  240         ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 33, 33, 80)   0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 31, 31, 192)  138240      ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 31, 31, 192)  576        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 31, 31, 192)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 15, 15, 192)  0          ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 15, 15, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 15, 15, 64)  192         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 15, 15, 48)   9216        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 15, 15, 96)   55296       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 15, 15, 48)  144         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 15, 15, 96)  288         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 15, 15, 48)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 15, 15, 96)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 15, 15, 192)  0          ['max_pooling2d_1[0][0]']        \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 15, 15, 64)   12288       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 15, 15, 64)   76800       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 15, 15, 96)   82944       ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 15, 15, 32)   6144        ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 15, 15, 64)  192         ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 15, 15, 64)  192         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 15, 15, 96)  288         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 15, 15, 32)  96          ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 15, 15, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 15, 15, 32)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)           (None, 15, 15, 256)  0           ['activation_5[0][0]',           \n",
            "                                                                  'activation_7[0][0]',           \n",
            "                                                                  'activation_10[0][0]',          \n",
            "                                                                  'activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 15, 15, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 15, 15, 64)  192         ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 15, 15, 48)   12288       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 15, 15, 96)   55296       ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 15, 15, 48)  144         ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 15, 15, 96)  288         ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 15, 15, 48)   0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_1 (AveragePo  (None, 15, 15, 256)  0          ['mixed0[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 15, 15, 64)   16384       ['mixed0[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 15, 15, 64)   76800       ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 15, 15, 96)   82944       ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 15, 15, 64)   16384       ['average_pooling2d_1[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 15, 15, 64)  192         ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 15, 15, 64)  192         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 15, 15, 96)  288         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 15, 15, 64)  192         ['conv2d_18[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)           (None, 15, 15, 288)  0           ['activation_12[0][0]',          \n",
            "                                                                  'activation_14[0][0]',          \n",
            "                                                                  'activation_17[0][0]',          \n",
            "                                                                  'activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 15, 15, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 15, 15, 64)  192         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 15, 15, 48)   13824       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 15, 15, 96)   55296       ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 15, 15, 48)  144         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 15, 15, 96)  288         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 15, 15, 48)   0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_2 (AveragePo  (None, 15, 15, 288)  0          ['mixed1[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 15, 15, 64)   18432       ['mixed1[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 15, 15, 64)   76800       ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 15, 15, 96)   82944       ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 15, 15, 64)   18432       ['average_pooling2d_2[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 15, 15, 64)  192         ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 15, 15, 64)  192         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 15, 15, 96)  288         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 15, 15, 64)  192         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)           (None, 15, 15, 288)  0           ['activation_19[0][0]',          \n",
            "                                                                  'activation_21[0][0]',          \n",
            "                                                                  'activation_24[0][0]',          \n",
            "                                                                  'activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 15, 15, 64)   18432       ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 15, 15, 64)  192         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 15, 15, 64)   0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 15, 15, 96)   55296       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 15, 15, 96)  288         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 15, 15, 96)   0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 7, 7, 384)    995328      ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 7, 7, 96)     82944       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 7, 7, 384)   1152        ['conv2d_26[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 7, 7, 96)    288         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 7, 7, 384)    0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 7, 7, 96)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)   0           ['mixed2[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)           (None, 7, 7, 768)    0           ['activation_26[0][0]',          \n",
            "                                                                  'activation_29[0][0]',          \n",
            "                                                                  'max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 7, 7, 128)   384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_34 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_34[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 7, 7, 128)   384         ['conv2d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_35 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 7, 7, 128)    98304       ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_35[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 7, 7, 128)   384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 7, 7, 128)   384         ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " activation_36 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 7, 7, 128)    114688      ['activation_36[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 7, 7, 128)   384         ['conv2d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 7, 7, 128)   384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " activation_37 (Activation)     (None, 7, 7, 128)    0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 7, 7, 768)   0           ['mixed3[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed3[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 7, 7, 192)    172032      ['activation_37[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 7, 7, 192)   576         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 7, 7, 192)   576         ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 7, 7, 192)   576         ['conv2d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 7, 7, 192)   576         ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " activation_38 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " activation_39 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)           (None, 7, 7, 768)    0           ['activation_30[0][0]',          \n",
            "                                                                  'activation_33[0][0]',          \n",
            "                                                                  'activation_38[0][0]',          \n",
            "                                                                  'activation_39[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 7, 7, 160)   480         ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_44 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_44[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 7, 7, 160)   480         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_45 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_45[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 7, 7, 160)   480         ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 7, 7, 160)   480         ['conv2d_46[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_41 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " activation_46 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_41[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_46[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 7, 7, 160)   480         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 7, 7, 160)   480         ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_42 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " activation_47 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_4 (AveragePo  (None, 7, 7, 768)   0           ['mixed4[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_42[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_47[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_4[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 7, 7, 192)   576         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 7, 7, 192)   576         ['conv2d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 7, 7, 192)   576         ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 7, 7, 192)   576         ['conv2d_49[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_40 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " activation_43 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " activation_48 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " activation_49 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)           (None, 7, 7, 768)    0           ['activation_40[0][0]',          \n",
            "                                                                  'activation_43[0][0]',          \n",
            "                                                                  'activation_48[0][0]',          \n",
            "                                                                  'activation_49[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_54 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_54 (BatchN  (None, 7, 7, 160)   480         ['conv2d_54[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_54 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_54[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_55 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_54[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_55 (BatchN  (None, 7, 7, 160)   480         ['conv2d_55[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_55 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_55[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_51 (Conv2D)             (None, 7, 7, 160)    122880      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_56 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_55[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 7, 7, 160)   480         ['conv2d_51[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_56 (BatchN  (None, 7, 7, 160)   480         ['conv2d_56[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_51 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " activation_56 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_56[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_52 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_51[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_57 (Conv2D)             (None, 7, 7, 160)    179200      ['activation_56[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 7, 7, 160)   480         ['conv2d_52[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_57 (BatchN  (None, 7, 7, 160)   480         ['conv2d_57[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_52 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_52[0][0]'] \n",
            "                                                                                                  \n",
            " activation_57 (Activation)     (None, 7, 7, 160)    0           ['batch_normalization_57[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_5 (AveragePo  (None, 7, 7, 768)   0           ['mixed5[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed5[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_53 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_52[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_58 (Conv2D)             (None, 7, 7, 192)    215040      ['activation_57[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_59 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_5[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 7, 7, 192)   576         ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_53 (BatchN  (None, 7, 7, 192)   576         ['conv2d_53[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_58 (BatchN  (None, 7, 7, 192)   576         ['conv2d_58[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_59 (BatchN  (None, 7, 7, 192)   576         ['conv2d_59[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_50 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " activation_53 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_53[0][0]'] \n",
            "                                                                                                  \n",
            " activation_58 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_58[0][0]'] \n",
            "                                                                                                  \n",
            " activation_59 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_59[0][0]'] \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)           (None, 7, 7, 768)    0           ['activation_50[0][0]',          \n",
            "                                                                  'activation_53[0][0]',          \n",
            "                                                                  'activation_58[0][0]',          \n",
            "                                                                  'activation_59[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_64 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_64 (BatchN  (None, 7, 7, 192)   576         ['conv2d_64[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_64 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_64[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_64[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_65 (BatchN  (None, 7, 7, 192)   576         ['conv2d_65[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_65 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_65[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_61 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_65[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_61 (BatchN  (None, 7, 7, 192)   576         ['conv2d_61[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_66 (BatchN  (None, 7, 7, 192)   576         ['conv2d_66[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_61 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_61[0][0]'] \n",
            "                                                                                                  \n",
            " activation_66 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_66[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_62 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_61[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_66[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_62 (BatchN  (None, 7, 7, 192)   576         ['conv2d_62[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_67 (BatchN  (None, 7, 7, 192)   576         ['conv2d_67[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_62 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_62[0][0]'] \n",
            "                                                                                                  \n",
            " activation_67 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_67[0][0]'] \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (AveragePo  (None, 7, 7, 768)   0           ['mixed6[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_60 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_63 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_62[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_67[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)             (None, 7, 7, 192)    147456      ['average_pooling2d_6[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_60 (BatchN  (None, 7, 7, 192)   576         ['conv2d_60[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_63 (BatchN  (None, 7, 7, 192)   576         ['conv2d_63[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_68 (BatchN  (None, 7, 7, 192)   576         ['conv2d_68[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_69 (BatchN  (None, 7, 7, 192)   576         ['conv2d_69[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_60 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_60[0][0]'] \n",
            "                                                                                                  \n",
            " activation_63 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_63[0][0]'] \n",
            "                                                                                                  \n",
            " activation_68 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_68[0][0]'] \n",
            "                                                                                                  \n",
            " activation_69 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_69[0][0]'] \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)           (None, 7, 7, 768)    0           ['activation_60[0][0]',          \n",
            "                                                                  'activation_63[0][0]',          \n",
            "                                                                  'activation_68[0][0]',          \n",
            "                                                                  'activation_69[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_72 (BatchN  (None, 7, 7, 192)   576         ['conv2d_72[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_72 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_72[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_72[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_73 (BatchN  (None, 7, 7, 192)   576         ['conv2d_73[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_73 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_73[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)             (None, 7, 7, 192)    147456      ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)             (None, 7, 7, 192)    258048      ['activation_73[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_70 (BatchN  (None, 7, 7, 192)   576         ['conv2d_70[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_74 (BatchN  (None, 7, 7, 192)   576         ['conv2d_74[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_70 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_70[0][0]'] \n",
            "                                                                                                  \n",
            " activation_74 (Activation)     (None, 7, 7, 192)    0           ['batch_normalization_74[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)             (None, 3, 3, 320)    552960      ['activation_70[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_75 (Conv2D)             (None, 3, 3, 192)    331776      ['activation_74[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_71 (BatchN  (None, 3, 3, 320)   960         ['conv2d_71[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_75 (BatchN  (None, 3, 3, 192)   576         ['conv2d_75[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_71 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_71[0][0]'] \n",
            "                                                                                                  \n",
            " activation_75 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_75[0][0]'] \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)   0           ['mixed7[0][0]']                 \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)           (None, 3, 3, 1280)   0           ['activation_71[0][0]',          \n",
            "                                                                  'activation_75[0][0]',          \n",
            "                                                                  'max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_80 (Conv2D)             (None, 3, 3, 448)    573440      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_80 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_80[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_80 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_80[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_77 (Conv2D)             (None, 3, 3, 384)    491520      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_81 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_80[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_77 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_77[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_81 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_81[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_77 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_77[0][0]'] \n",
            "                                                                                                  \n",
            " activation_81 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_81[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_78 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_79 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_77[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_82 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_83 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_81[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_7 (AveragePo  (None, 3, 3, 1280)  0           ['mixed8[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_76 (Conv2D)             (None, 3, 3, 320)    409600      ['mixed8[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_78 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_78[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_79 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_79[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_82 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_82[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_83 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_83[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_84 (Conv2D)             (None, 3, 3, 192)    245760      ['average_pooling2d_7[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_76 (BatchN  (None, 3, 3, 320)   960         ['conv2d_76[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_78 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_78[0][0]'] \n",
            "                                                                                                  \n",
            " activation_79 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_79[0][0]'] \n",
            "                                                                                                  \n",
            " activation_82 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_82[0][0]'] \n",
            "                                                                                                  \n",
            " activation_83 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_83[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_84 (BatchN  (None, 3, 3, 192)   576         ['conv2d_84[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_76 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_76[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)         (None, 3, 3, 768)    0           ['activation_78[0][0]',          \n",
            "                                                                  'activation_79[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 3, 3, 768)    0           ['activation_82[0][0]',          \n",
            "                                                                  'activation_83[0][0]']          \n",
            "                                                                                                  \n",
            " activation_84 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_84[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)           (None, 3, 3, 2048)   0           ['activation_76[0][0]',          \n",
            "                                                                  'mixed9_0[0][0]',               \n",
            "                                                                  'concatenate[0][0]',            \n",
            "                                                                  'activation_84[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_89 (Conv2D)             (None, 3, 3, 448)    917504      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_89 (BatchN  (None, 3, 3, 448)   1344        ['conv2d_89[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_89 (Activation)     (None, 3, 3, 448)    0           ['batch_normalization_89[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_86 (Conv2D)             (None, 3, 3, 384)    786432      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_90 (Conv2D)             (None, 3, 3, 384)    1548288     ['activation_89[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_86 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_86[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_90 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_90[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_86 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_86[0][0]'] \n",
            "                                                                                                  \n",
            " activation_90 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_90[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_87 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_88 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_86[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_91 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_92 (Conv2D)             (None, 3, 3, 384)    442368      ['activation_90[0][0]']          \n",
            "                                                                                                  \n",
            " average_pooling2d_8 (AveragePo  (None, 3, 3, 2048)  0           ['mixed9[0][0]']                 \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " conv2d_85 (Conv2D)             (None, 3, 3, 320)    655360      ['mixed9[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_87 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_87[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_88 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_88[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_91 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_91[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " batch_normalization_92 (BatchN  (None, 3, 3, 384)   1152        ['conv2d_92[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_93 (Conv2D)             (None, 3, 3, 192)    393216      ['average_pooling2d_8[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_85 (BatchN  (None, 3, 3, 320)   960         ['conv2d_85[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_87 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_87[0][0]'] \n",
            "                                                                                                  \n",
            " activation_88 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_88[0][0]'] \n",
            "                                                                                                  \n",
            " activation_91 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_91[0][0]'] \n",
            "                                                                                                  \n",
            " activation_92 (Activation)     (None, 3, 3, 384)    0           ['batch_normalization_92[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_93 (BatchN  (None, 3, 3, 192)   576         ['conv2d_93[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_85 (Activation)     (None, 3, 3, 320)    0           ['batch_normalization_85[0][0]'] \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)         (None, 3, 3, 768)    0           ['activation_87[0][0]',          \n",
            "                                                                  'activation_88[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 3, 3, 768)    0           ['activation_91[0][0]',          \n",
            "                                                                  'activation_92[0][0]']          \n",
            "                                                                                                  \n",
            " activation_93 (Activation)     (None, 3, 3, 192)    0           ['batch_normalization_93[0][0]'] \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)          (None, 3, 3, 2048)   0           ['activation_85[0][0]',          \n",
            "                                                                  'mixed9_1[0][0]',               \n",
            "                                                                  'concatenate_1[0][0]',          \n",
            "                                                                  'activation_93[0][0]']          \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 2048)        0           ['mixed10[0][0]']                \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 1024)         2098176     ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 7)            7175        ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,908,135\n",
            "Trainable params: 23,873,703\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data_x, train_data_y, epochs=5, validation_data=val_data)"
      ],
      "metadata": {
        "id": "LZdpuFo5tHJ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CV Project",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}